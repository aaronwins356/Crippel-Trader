"""Autonomous code refinement agent for Croc-Bot."""
from __future__ import annotations

import json
import logging
import os
import shutil
import subprocess
import tempfile
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Iterable, Mapping, MutableMapping, Protocol, Sequence

logger = logging.getLogger(__name__)


class IssueSeverity(str, Enum):
    """Enumeration describing the criticality of an issue."""

    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

    @property
    def priority(self) -> int:
        return {
            IssueSeverity.INFO: 0,
            IssueSeverity.WARNING: 1,
            IssueSeverity.ERROR: 2,
            IssueSeverity.CRITICAL: 3,
        }[self]


@dataclass(slots=True)
class Issue:
    """Represents an operational or performance problem detected by the agent."""

    identifier: str
    summary: str
    severity: IssueSeverity
    evidence: Mapping[str, Any]
    metadata: MutableMapping[str, Any] = field(default_factory=dict)

    def fingerprint(self) -> str:
        """Stable fingerprint for deduplicating recurring issues."""

        payload = json.dumps(
            {
                "summary": self.summary,
                "severity": self.severity.value,
                "evidence": self.evidence,
                "metadata": self.metadata,
            },
            sort_keys=True,
        )
        return str(hash(payload))


@dataclass(slots=True)
class PatchProposal:
    """Proposed modification generated by the LLM."""

    issue_id: str
    summary: str
    diff: str
    confidence: float
    rationale: str

    def changed_paths(self) -> set[Path]:
        """Infer modified files from the unified diff headers."""

        paths: set[Path] = set()
        for line in self.diff.splitlines():
            if line.startswith("+++ b/"):
                paths.add(Path(line[6:]))
        return paths


@dataclass(slots=True)
class TestCommandResult:
    """Represents the outcome of a validation command."""

    command: Sequence[str]
    return_code: int
    stdout: str
    stderr: str

    @property
    def succeeded(self) -> bool:
        return self.return_code == 0


@dataclass(slots=True)
class ValidationReport:
    """Aggregated validation results for a patch proposal."""

    proposal: PatchProposal
    syntax_ok: bool
    tests: tuple[TestCommandResult, ...]
    applied: bool

    @property
    def passed(self) -> bool:
        return self.syntax_ok and all(result.succeeded for result in self.tests)


class LLMClient(Protocol):
    """Protocol describing the minimum surface for an LLM integration."""

    def analyze_issue(self, issue: Issue, code_context: str) -> str:
        """Return a natural-language analysis for the supplied issue."""

    def propose_patch(self, issue: Issue, code_context: str) -> PatchProposal | None:
        """Return a unified diff implementing the recommended fix."""


@dataclass(slots=True)
class AIAgentConfig:
    """Configuration bundle for the autonomous refactor agent."""

    repo_root: Path
    log_path: Path
    metrics_path: Path | None = None
    apply_changes: bool = False
    max_loop_latency_ms: float = 250.0
    error_burst_threshold: int = 3
    min_confidence: float = 0.55
    context_radius: int = 30
    test_commands: tuple[Sequence[str], ...] = (("pytest",),)

    def __post_init__(self) -> None:
        self.repo_root = self.repo_root.resolve()
        self.log_path = self.log_path.resolve()
        if self.metrics_path is not None:
            self.metrics_path = self.metrics_path.resolve()


class LogAnalyzer:
    """Parse structured logs and emit issues based on heuristics."""

    def __init__(self, log_path: Path, *, latency_threshold_ms: float, error_burst_threshold: int) -> None:
        self._log_path = log_path
        self._latency_threshold = latency_threshold_ms / 1000.0
        self._error_burst_threshold = error_burst_threshold

    def collect(self) -> list[Issue]:
        if not self._log_path.exists():
            logger.debug("Log path %s does not exist; skipping analysis", self._log_path)
            return []

        issues: list[Issue] = []
        error_buffer: list[dict[str, Any]] = []

        with self._log_path.open("r", encoding="utf-8") as handle:
            for line_number, raw in enumerate(handle, start=1):
                raw = raw.strip()
                if not raw:
                    continue
                try:
                    entry: dict[str, Any] = json.loads(raw)
                except json.JSONDecodeError:
                    logger.debug("Skipping non-JSON log line %s", raw)
                    continue

                event = entry.get("event") or entry.get("msg") or entry.get("message")

                if event == "market_tick":
                    latency = float(entry.get("loop_latency", 0.0))
                    if latency > self._latency_threshold:
                        issues.append(
                            Issue(
                                identifier=f"latency-{line_number}",
                                summary="Engine loop latency exceeded threshold",
                                severity=IssueSeverity.WARNING,
                                evidence={"loop_latency": latency, "threshold": self._latency_threshold},
                                metadata={
                                    "suspect": "croc_bot/orchestration/engine.py",
                                    "log_line": line_number,
                                },
                            )
                        )

                if "error" in entry or entry.get("level") in {"error", "exception", "critical"}:
                    error_buffer.append(entry)
                    if len(error_buffer) >= self._error_burst_threshold:
                        evidence = {
                            "count": len(error_buffer),
                            "messages": [item.get("error") or item.get("event") for item in error_buffer],
                        }
                        metadata: dict[str, Any] = {
                            "timestamp": error_buffer[-1].get("timestamp"),
                        }
                        traceback = error_buffer[-1].get("traceback") or error_buffer[-1].get("exc_info")
                        if traceback:
                            metadata["traceback"] = traceback
                            suspect = self._extract_suspect(traceback)
                            if suspect:
                                metadata["suspect"] = suspect
                        issues.append(
                            Issue(
                                identifier=f"error-burst-{line_number}",
                                summary="Repeated errors detected in logs",
                                severity=IssueSeverity.CRITICAL,
                                evidence=evidence,
                                metadata=metadata,
                            )
                        )
                        error_buffer.clear()
                else:
                    error_buffer.clear()

        return issues

    @staticmethod
    def _extract_suspect(traceback: str) -> str | None:
        for line in traceback.splitlines():
            line = line.strip()
            if line.startswith("File ") and ", line " in line:
                parts = line.split(", line ", maxsplit=1)
                if parts:
                    file_fragment = parts[0].replace("File", "").strip().strip("\"")
                    return os.path.relpath(file_fragment)
        return None


class MetricsAnalyzer:
    """Detect performance regressions based on recorded metrics."""

    def __init__(self, metrics_path: Path | None, *, latency_threshold_ms: float) -> None:
        self._metrics_path = metrics_path
        self._latency_threshold_ms = latency_threshold_ms

    def collect(self) -> list[Issue]:
        if self._metrics_path is None or not self._metrics_path.exists():
            return []

        try:
            payload = json.loads(self._metrics_path.read_text(encoding="utf-8"))
        except json.JSONDecodeError:
            logger.warning("Metrics file %s is not valid JSON", self._metrics_path)
            return []

        issues: list[Issue] = []
        latency_p95 = float(payload.get("loop_latency_p95_ms", 0.0))
        if latency_p95 > self._latency_threshold_ms:
            issues.append(
                Issue(
                    identifier="metrics-latency",
                    summary="Loop latency p95 breached threshold",
                    severity=IssueSeverity.WARNING,
                    evidence={
                        "p95_ms": latency_p95,
                        "threshold_ms": self._latency_threshold_ms,
                    },
                    metadata={"suspect": "croc_bot/orchestration/engine.py"},
                )
            )

        win_rate = payload.get("win_rate")
        if isinstance(win_rate, (int, float)) and win_rate < payload.get("win_rate_baseline", 0.0):
            issues.append(
                Issue(
                    identifier="metrics-win-rate",
                    summary="Observed win rate regressed below baseline",
                    severity=IssueSeverity.ERROR,
                    evidence={
                        "win_rate": win_rate,
                        "baseline": payload.get("win_rate_baseline"),
                    },
                    metadata={"suspect": "strategies"},
                )
            )

        return issues


class CodebaseInspector:
    """Utility for extracting contextual code snippets for an issue."""

    def __init__(self, root: Path, *, context_radius: int) -> None:
        self._root = root
        self._radius = context_radius

    def extract(self, issue: Issue) -> str:
        suspect = issue.metadata.get("suspect") if isinstance(issue.metadata, Mapping) else None
        if isinstance(suspect, str):
            path = (self._root / suspect).resolve()
            if path.exists() and path.is_file():
                return self._read_with_context(path, line_number=self._line_number(issue))

        return ""

    def _line_number(self, issue: Issue) -> int | None:
        line = issue.metadata.get("line") if isinstance(issue.metadata, Mapping) else None
        if isinstance(line, int) and line > 0:
            return line
        traceback = issue.metadata.get("traceback") if isinstance(issue.metadata, Mapping) else None
        if isinstance(traceback, str):
            for frame in traceback.splitlines()[::-1]:
                frame = frame.strip()
                if frame.startswith("File ") and ", line " in frame:
                    try:
                        return int(frame.split(", line ", maxsplit=1)[1].split(",")[0])
                    except (IndexError, ValueError):  # pragma: no cover - defensive
                        continue
        return None

    def _read_with_context(self, path: Path, line_number: int | None) -> str:
        lines = path.read_text(encoding="utf-8").splitlines()
        if line_number is None:
            excerpt = lines[-self._radius :]
            return "\n".join(excerpt)

        start = max(line_number - self._radius, 0)
        end = min(line_number + self._radius, len(lines))
        snippet = lines[start:end]
        header = f"# Context: {path.relative_to(self._root)} lines {start + 1}-{end}"
        return "\n".join([header, *snippet])


class RepositoryManager:
    """Lightweight helper for manipulating repository state safely."""

    def __init__(self, root: Path) -> None:
        self._root = root

    def apply_diff(self, diff: str, *, reverse: bool = False) -> None:
        self._run_git_apply(diff, check_only=False, reverse=reverse)

    def check_diff(self, diff: str) -> bool:
        return self._run_git_apply(diff, check_only=True)

    def _run_git_apply(self, diff: str, *, check_only: bool, reverse: bool = False) -> bool:
        if not diff.strip():
            return False

        cmd = ["git", "apply"]
        if check_only:
            cmd.append("--check")
        if reverse:
            cmd.append("-R")

        proc = subprocess.run(
            cmd,
            input=diff.encode("utf-8"),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=self._root,
            check=False,
        )
        if proc.return_code != 0:
            logger.debug("git apply failed: %s", proc.stderr.decode("utf-8", errors="ignore"))
            return False
        return True


class PatchValidator:
    """Validate code proposals by applying them in a temporary workspace."""

    def __init__(self, config: AIAgentConfig) -> None:
        self._config = config

    def validate(self, proposal: PatchProposal) -> ValidationReport:
        syntax_ok = False
        test_results: list[TestCommandResult] = []

        if not proposal.diff.strip():
            return ValidationReport(proposal=proposal, syntax_ok=False, tests=tuple(), applied=False)

        with tempfile.TemporaryDirectory(prefix="croc-agent-") as tmp:
            tmp_path = Path(tmp) / "repo"
            shutil.copytree(self._config.repo_root, tmp_path)

            proc = subprocess.run(
                ["git", "apply"],
                input=proposal.diff.encode("utf-8"),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=tmp_path,
                check=False,
            )
            if proc.return_code != 0:
                logger.warning(
                    "Failed to apply diff in validation workspace: %s",
                    proc.stderr.decode("utf-8", errors="ignore"),
                )
                return ValidationReport(
                    proposal=proposal,
                    syntax_ok=False,
                    tests=tuple(),
                    applied=False,
                )

            python_files = [
                tmp_path / path
                for path in proposal.changed_paths()
                if (tmp_path / path).suffix == ".py"
            ]

            syntax_ok = self._compile_sources(python_files)

            if syntax_ok:
                for command in self._config.test_commands:
                    result = self._run_command(command, cwd=tmp_path)
                    test_results.append(result)
                    if not result.succeeded:
                        break

        return ValidationReport(
            proposal=proposal,
            syntax_ok=syntax_ok,
            tests=tuple(test_results),
            applied=False,
        )

    @staticmethod
    def _compile_sources(files: Iterable[Path]) -> bool:
        if not files:
            return True
        import py_compile

        for file in files:
            try:
                py_compile.compile(str(file), doraise=True)
            except py_compile.PyCompileError as exc:
                logger.warning("Syntax check failed for %s: %s", file, exc)
                return False
        return True

    @staticmethod
    def _run_command(command: Sequence[str], *, cwd: Path) -> TestCommandResult:
        proc = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=cwd,
            check=False,
        )
        return TestCommandResult(
            command=tuple(command),
            return_code=proc.return_code,
            stdout=proc.stdout.decode("utf-8", errors="ignore"),
            stderr=proc.stderr.decode("utf-8", errors="ignore"),
        )


class MemoryKnowledgeBase:
    """Simple in-memory knowledge base for tracking recurring issues."""

    def __init__(self) -> None:
        self._store: dict[str, Issue] = {}

    def record(self, issue: Issue) -> None:
        self._store[issue.fingerprint()] = issue

    def seen(self, issue: Issue) -> bool:
        return issue.fingerprint() in self._store


class NoOpLLMClient(LLMClient):
    """Fallback LLM client that records intent without generating patches."""

    def analyze_issue(self, issue: Issue, code_context: str) -> str:  # noqa: D401 - protocol implementation
        return (
            "NoOpLLMClient configured. Provide a concrete LLMClient implementation "
            "to enable autonomous remediation."
        )

    def propose_patch(self, issue: Issue, code_context: str) -> PatchProposal | None:
        return None


class AICodeRefactorAgent:
    """Autonomous agent that closes the loop between monitoring and refactoring."""

    def __init__(self, config: AIAgentConfig, llm_client: LLMClient) -> None:
        self._config = config
        self._llm = llm_client
        self._log_analyzer = LogAnalyzer(
            config.log_path,
            latency_threshold_ms=config.max_loop_latency_ms,
            error_burst_threshold=config.error_burst_threshold,
        )
        self._metrics_analyzer = MetricsAnalyzer(
            config.metrics_path,
            latency_threshold_ms=config.max_loop_latency_ms,
        )
        self._inspector = CodebaseInspector(config.repo_root, context_radius=config.context_radius)
        self._validator = PatchValidator(config)
        self._repo = RepositoryManager(config.repo_root)
        self._knowledge = MemoryKnowledgeBase()

    def run_cycle(self) -> list[ValidationReport]:
        """Execute a full monitoring-analyze-propose-validate cycle."""

        issues = self._gather_issues()
        reports: list[ValidationReport] = []

        for issue in issues:
            if self._knowledge.seen(issue):
                logger.debug("Skipping previously recorded issue: %s", issue.summary)
                continue

            self._knowledge.record(issue)

            code_context = self._inspector.extract(issue)
            analysis = self._llm.analyze_issue(issue, code_context)
            logger.info("Issue analysis for %s: %s", issue.identifier, analysis)

            proposal = self._llm.propose_patch(issue, code_context)
            if proposal is None:
                logger.info("LLM did not return a patch for issue %s", issue.identifier)
                continue

            if proposal.confidence < self._config.min_confidence:
                logger.info(
                    "Rejected patch for %s due to low confidence %.2f",
                    issue.identifier,
                    proposal.confidence,
                )
                continue

            if not self._repo.check_diff(proposal.diff):
                logger.info("Proposed diff for %s failed dry-run application", issue.identifier)
                continue

            report = self._validator.validate(proposal)
            reports.append(report)

            if report.passed and self._config.apply_changes:
                self._repo.apply_diff(proposal.diff)
                reports[-1] = ValidationReport(
                    proposal=proposal,
                    syntax_ok=report.syntax_ok,
                    tests=report.tests,
                    applied=True,
                )

        return reports

    def _gather_issues(self) -> list[Issue]:
        issues = self._log_analyzer.collect()
        issues.extend(self._metrics_analyzer.collect())
        issues.sort(key=lambda item: item.severity.priority, reverse=True)
        return issues
